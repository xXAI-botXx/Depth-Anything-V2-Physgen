{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72115f71",
   "metadata": {},
   "source": [
    "# Evaluation of 1 Model With Physgen\n",
    "-> Phys Anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28edf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"phys_any_1\"\n",
    "physgen_variation = \"sound_reflection\"    # sound_baseline, sound_reflection, sound_diffraction, sound_combined\n",
    "encoder = \"vitl\"    # vits, vitb, vitl, vitg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27adeb9e",
   "metadata": {},
   "source": [
    "### Env Setup\n",
    "\n",
    "Follow the README  env installation steps and set 'phy_any' as the active python env."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fad5b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac171a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f357709f",
   "metadata": {},
   "source": [
    "### Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title=None, image_width=10, axis=False,\n",
    "           color_space=\"RGB\", cmap=None, cols=1, save_to=None,\n",
    "           hspace=0.2, wspace=0.2,\n",
    "           use_original_sytle=False, invert=False):\n",
    "    \"\"\"\n",
    "    Visualizes one or multiple images.\n",
    "\n",
    "    Image will be reshaped: [batch_size/images, width, height, channels]\n",
    "\n",
    "    ---\n",
    "    Parameters:\n",
    "    - img : np.ndarray\n",
    "        Images/Images with [width, height, channels] or for multiple: [batch_size/images, width, height, channels].\n",
    "    - title : str, optional (default=None)\n",
    "        Title of the whole plot.\n",
    "    - image_width : int, optional (default=5)\n",
    "        Width of one image in the plot.\n",
    "    - axis : bool, optional (default=False)\n",
    "        Whether to print the axis of the images or not.\n",
    "    - color_space : str, optional (default=\"RGB\")\n",
    "        The colorspace of the image: RGB, BGR, gray, HSV.\n",
    "    - cmap : str, optional (default=None)\n",
    "        Which cmap to use. Check all cmaps here out: https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "    - cols : int, optional (default=1)\n",
    "        Amount of columns in the plot.\n",
    "    - save_to : str, optional (default=None)\n",
    "        Path where to save the result image.\n",
    "    - hspace : float, optional (default=0.01)\n",
    "        Horizontal space between the images.\n",
    "    - wspace : float, optional (default=0.01)\n",
    "        Vertical space between the images.\n",
    "    - use_original_sytle : bool, optonial (default=False)\n",
    "        Whether the plot should use the current active matplotlib style or choosing a own one. \n",
    "    - invert : bool, optional (default=False)\n",
    "        Whether to invert the images or not.\n",
    "    \"\"\"\n",
    "    original_style = plt.rcParams.copy()\n",
    "\n",
    "    img_shape = img.shape\n",
    "    print(f\"Got images with shape: {img_shape}\")\n",
    "\n",
    "    # tranform the image to the right form\n",
    "    if len(img_shape) == 2:\n",
    "        img = np.reshape(img, shape=(1, img.shape[0], img.shape[1], 1))\n",
    "    elif len(img_shape) == 3:\n",
    "        # check if multiple gray images or multiple images with channel\n",
    "        # if img.shape[2] < img.shape[0] and img.shape[1] == img.shape[2]:\n",
    "        img = np.reshape(img, shape=(1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "        # else:\n",
    "        #     # there could be cases where this is wrong\n",
    "        #     img = np.reshape(img, shape=(img.shape[0], img.shape[1], img.shape[2], 1))\n",
    "    elif len(img_shape) != 4:\n",
    "        raise ValueError(f\"Image(s) have wrong shape! Founded shape: {img.shape}.\")\n",
    "\n",
    "    print(f\"Transformed shape to: {img_shape}\")\n",
    "\n",
    "    # invert images\n",
    "    if invert:\n",
    "        print(\"Invert images...\")\n",
    "        max_value = 2**(img.dtype.itemsize * 8) -1\n",
    "        scaling_func = lambda x: max_value - x\n",
    "        img = np.apply_along_axis(scaling_func, axis=0, arr=img)\n",
    "\n",
    "    # Set visualization settings\n",
    "    # aspect_ratio_width = img.shape[1] / img.shape[2]\n",
    "    aspect_ratio = img.shape[2] / img.shape[1]\n",
    "\n",
    "    n_images = img.shape[0]\n",
    "    rows = n_images//cols + int(n_images % cols > 0)\n",
    "\n",
    "    width = int(image_width * cols)\n",
    "    height = int(image_width * rows * aspect_ratio)\n",
    "\n",
    "    # set plt style\n",
    "    if not use_original_sytle:\n",
    "        plt_style = 'seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else np.random.choice(plt.style.available)\n",
    "        plt.style.use(plt_style)\n",
    "        print(f\"Using '{plt_style}' plotting style.\")\n",
    "\n",
    "    # plotting\n",
    "    print(f\"Making you a beautiful plot...\")\n",
    "    fig, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(width, height))\n",
    "    try:\n",
    "        ax = ax.ravel()\n",
    "    except AttributeError:\n",
    "        ax = [ax]\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "    if type(title) == str:\n",
    "        fig.suptitle(title, fontsize=128, y=0.95)\n",
    "\n",
    "    for idx in range(len(ax)):\n",
    "        cur_ax = ax[idx]\n",
    "\n",
    "        if idx >= len(img):\n",
    "            cur_ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        cur_img = img[idx]\n",
    "\n",
    "        if color_space.lower() == \"bgr\":\n",
    "            cur_img = cv2.cvtColor(cur_img, cv2.COLOR_BGR2RGB)\n",
    "            used_cmap = None\n",
    "        elif color_space.lower() == \"rgb\":\n",
    "            cur_img = cur_img\n",
    "            used_cmap = None\n",
    "        elif color_space.lower() == \"hsv\":\n",
    "            cur_img = cv2.cvtColor(cur_img, cv2.COLOR_HSV2RGB)\n",
    "            used_cmap = None\n",
    "        elif color_space.lower() in [\"gray\", \"grey\", \"g\"]:\n",
    "            if len(cur_img.shape) == 3 and cur_img.shape[2]:\n",
    "                cur_img = cv2.cvtColor(cur_img, cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                cur_img = cur_img\n",
    "            print(cur_img.shape)\n",
    "            used_cmap = \"gray\"\n",
    "\n",
    "        if cmap:\n",
    "            used_cmap = cmap\n",
    "\n",
    "        if type(title) in [list, tuple]:\n",
    "            cur_ax.set_title(title[idx], fontsize=64)\n",
    "        if axis == False:\n",
    "            cur_ax.axis(\"off\")\n",
    "\n",
    "        cur_ax.imshow(cur_img, cmap=used_cmap)\n",
    "\n",
    "    if save_to:\n",
    "        os.makedirs(os.path.split(save_to)[0], exist_ok=True)\n",
    "        fig.savefig(save_to, dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if not use_original_sytle:\n",
    "        # reset to original plt style\n",
    "        plt.rcParams.update(original_style)\n",
    "\n",
    "def show_images(image_paths:list, title=None, image_width=5, axis=False,\n",
    "                color_space=\"gray\", cmap=None, \n",
    "                cols=2, save_to=None,\n",
    "                hspace=0.01, wspace=0.01,\n",
    "                use_original_sytle=False, invert=False):\n",
    "    \"\"\"\n",
    "    Visulalizes/shows one or multiple images.\n",
    "\n",
    "    ---\n",
    "    Parameters:\n",
    "    - image_paths : List[str]\n",
    "        List of paths to the images which should get visualized.\n",
    "    - title : str, optional (default=None)\n",
    "        Title of the whole plot.\n",
    "    - image_width : int, optional (default=5)\n",
    "        Width of one image in the plot.\n",
    "    - axis : bool, optional (default=False)\n",
    "        Whether to print the axis of the images or not.\n",
    "    - color_space : str, optional (default=\"RGB\")\n",
    "        The colorspace of the image: RGB, BGR, gray, HSV.\n",
    "    - cmap : str, optional (default=None)\n",
    "        Which cmap to use. Check all cmaps here out: https://matplotlib.org/stable/users/explain/colors/colormaps.html\n",
    "    - cols : int, optional (default=1)\n",
    "        Amount of columns in the plot.\n",
    "    - save_to : str, optional (default=None)\n",
    "        Path where to save the result image.\n",
    "    - hspace : float, optional (default=0.01)\n",
    "        Horizontal space between the images.\n",
    "    - wspace : float, optional (default=0.01)\n",
    "        Vertical space between the images.\n",
    "    - use_original_sytle : bool, optonial (default=False)\n",
    "        Whether the plot should use the current active matplotlib style or choosing a own one. \n",
    "    - invert : bool, optional (default=False)\n",
    "        Whether to invert the images or not.\n",
    "    \"\"\"\n",
    "    if color_space.lower() == \"rgb\":\n",
    "        images = np.array([cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB) for img in image_paths])\n",
    "    elif color_space.lower() == \"hsv\":\n",
    "        images = np.array([cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2HSV) for img in image_paths])\n",
    "    else:\n",
    "        images = np.array([cv2.imread(img) for img in image_paths])\n",
    "    imshow(images, title=title, image_width=image_width, axis=axis,\n",
    "           color_space=color_space, cmap=cmap, cols=cols, save_to=save_to,\n",
    "           hspace=hspace, wspace=wspace,\n",
    "           use_original_sytle=use_original_sytle, invert=invert)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1583ad16",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c413c",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = (\n",
    "  f\"python inference.py \"\n",
    "  f\"--variation {variation} \"\n",
    "  f\"--model_name {model_name} \"\n",
    "  f\"--encoder {encoder} \"\n",
    "  # f\"--save_only_result\"\n",
    ")\n",
    "\n",
    "# Finally run it\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7849e54",
   "metadata": {},
   "source": [
    "### Calc Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861533a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python eval_metrics.py \\\n",
    "    --data_dir ./eval/{model_name}/real \\\n",
    "    --pred_dir ./eval/{model_name}/pred \\\n",
    "    --osm_dir ./eval/{model_name}/osm \\\n",
    "    --output ./eval_results/evaluation_{model_name}.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c3f50",
   "metadata": {},
   "source": [
    "### Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96137cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_model_name = f'MAE_{model_name}'\n",
    "los_mae_model_name = f'LoS_MAE_{model_name}'\n",
    "nlos_mae_model_name = f'NLoS_MAE_{model_name}'\n",
    "mape_model_name = f'MAPE_{model_name}'\n",
    "los_wmape_model_name = f'LoS_wMAPE_{model_name}'\n",
    "nlos_wmape_model_name = f'NLoS_wMAPE_{model_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b0759",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(f\"./eval_results/evaluation_{model_name}.csv\")\n",
    "# df_1 = df_1.drop(columns=[\"LoS_MAE\", \"NLoS_MAE\", \"LoS_wMAPE\", \"NLoS_wMAPE\"])\n",
    "df_1 = df_1.rename(columns={'MAE': mae_model_name, \n",
    "                            'LoS_MAE': los_mae_model_name,\n",
    "                            'NLoS_MAE': nlos_mae_model_name,\n",
    "                            'MAPE':mape_model_name,\n",
    "                            'LoS_wMAPE': los_wmape_model_name,\n",
    "                            'NLoS_wMAPE': nlos_wmape_model_name\n",
    "                            }\n",
    "                   )\n",
    "# extract sample_ids\n",
    "sample_id_series = df_1[\"sample_id\"].str.extract(r'^(\\d+)_')[0]\n",
    "if sample_id_series.isna().sum() > 1:\n",
    "    sample_id_series = df_1[\"sample_id\"].str.extract(r'(\\d+)')[0]\n",
    "if sample_id_series.isna().sum() > 1:\n",
    "    raise ValueError(f\"Found {sample_id_series.isna().sum()} Nans\")\n",
    "df_1[\"sample_id\"] = sample_id_series\n",
    "print(\"Nan found in sample ids:\", df_1[\"sample_id\"].isna().sum())\n",
    "df_1 = df_1.dropna(subset=[\"sample_id\"])\n",
    "df_1[\"sample_id\"] = df_1[\"sample_id\"].astype(int)\n",
    "merged_df = df_1\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385206db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_style = 'seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else np.random.choice(plt.style.available)\n",
    "plt.style.use(plt_style)\n",
    "print(f\"Using '{plt_style}' plotting style.\")\n",
    "\n",
    "values = [\n",
    "    merged_df[mae_model_name],\n",
    "    merged_df[mape_model_name],\n",
    "    merged_df[los_mae_model_name],\n",
    "    merged_df[nlos_mae_model_name],\n",
    "    merged_df[los_wmape_model_name],\n",
    "    merged_df[nlos_wmape_model_name]\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"MAE\",\n",
    "    \"MAPE\",\n",
    "    \"LoS MAE\",\n",
    "    \"NLoS MAE\",\n",
    "    \"LoS wMAPE\",\n",
    "    \"NLoS wMAPE\"\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.boxplot(values, notch=False)\n",
    "ax.set_xticks(range(1, len(labels) + 1))\n",
    "ax.set_xticklabels(labels, rotation=15)\n",
    "ax.set_title(\"Error Metrics Distribution\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nMAE: {merged_df[mae_model_name].mean():>0.2f}\")\n",
    "print(f\"\\nMAPE: {merged_df[mape_model_name].mean():>0.2f}\")\n",
    "print(f\"\\nLoS MAE: {merged_df[los_mae_model_name].mean():>0.2f}\")\n",
    "print(f\"\\nNLoS MAE: {merged_df[nlos_mae_model_name].mean():>0.2f}\")\n",
    "print(f\"\\nLoS wMAPE: {merged_df[los_wmape_model_name].mean():>0.2f}\")\n",
    "print(f\"\\nNLoS wMAPE: {merged_df[nlos_wmape_model_name].mean():>0.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ddf2ca",
   "metadata": {},
   "source": [
    "Example Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1e1dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_same_pred_real_samples(pred_path:str, real_path:str, n_samples:int, ids=None):\n",
    "    if not ids:\n",
    "        # choose n random samples\n",
    "        samples = random.sample(os.listdir(pred_path), n_samples)\n",
    "        result_samples = [os.path.join(pred_path, cur_image) for cur_image in samples]\n",
    "\n",
    "        # get the used id's\n",
    "        ids = []\n",
    "        for cur_image in samples:\n",
    "            cur_id = re.findall(r'\\d+', string=cur_image)\n",
    "            if len(cur_id) > 1:\n",
    "                raise ValueError(\"Too many ids found!\")\n",
    "            cur_id = cur_id[0]\n",
    "            if len(cur_id) <= 0:\n",
    "                raise ValueError(f\"One image has no ID: {cur_image}\")\n",
    "            ids += [cur_id]\n",
    "    else:\n",
    "        # get pred image\n",
    "        pred_image_samples = []\n",
    "        for target_id in ids:\n",
    "            found = False\n",
    "            for cur_image in os.listdir(real_path):\n",
    "                cur_id = re.findall('\\d+', string=cur_image)\n",
    "                if len(cur_id) > 1:\n",
    "                    raise ValueError(f\"Too many ids found in {cur_image}!\")\n",
    "                elif len(cur_id) <= 0:\n",
    "                    continue\n",
    "                    # raise ValueError(f\"No id found in {cur_image}!\")\n",
    "                cur_id = cur_id[0]\n",
    "                if cur_id == target_id:\n",
    "                    pred_image_samples += [cur_image]\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                raise ValueError(f\"Does not found pred image with id: {target_id}\")\n",
    "        result_samples = [os.path.join(pred_path, cur_image) for cur_image in pred_image_samples]\n",
    "\n",
    "    # get real image\n",
    "    real_image_samples = []\n",
    "    for target_id in ids:\n",
    "        found = False\n",
    "        for cur_image in os.listdir(real_path):\n",
    "            cur_id = re.findall('\\d+', string=cur_image)\n",
    "            if len(cur_id) > 1:\n",
    "                raise ValueError(f\"Too many ids found in {cur_image}!\")\n",
    "            elif len(cur_id) <= 0:\n",
    "                continue\n",
    "                # raise ValueError(f\"No id found in {cur_image}!\")\n",
    "            cur_id = cur_id[0]\n",
    "            if cur_id == target_id:\n",
    "                real_image_samples += [cur_image]\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            raise ValueError(f\"Does not found real image with id: {target_id}\")\n",
    "\n",
    "    result_samples += [os.path.join(real_path, cur_image) for cur_image in real_image_samples]\n",
    "\n",
    "    return result_samples, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4017da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def get_unique_hsv_cmap():\n",
    "    unique_hsv_map = plt.get_cmap(\"hsv\")(np.linspace(0, 1, 256))    # np.arange(0, 256)\n",
    "    hsv_map = plt.get_cmap(\"hsv\")\n",
    "    for cur_idx in range(256):\n",
    "        r, g, b, a = hsv_map(cur_idx)\n",
    "        if r > 0.99 and g < (170/255):\n",
    "            gray_value = cur_idx*8 / 255.0\n",
    "            unique_hsv_map[cur_idx] = (gray_value, gray_value, gray_value, 1.0)\n",
    "        else:\n",
    "            break\n",
    "    unique_hsv = ListedColormap(unique_hsv_map)\n",
    "    plt.colormaps.register(name=\"unique_hsv\", cmap=unique_hsv, force=True)\n",
    "    return unique_hsv\n",
    "\n",
    "# for i in range(256):\n",
    "#     print([int(cur_color*255) for cur_color in get_cmap('hsv')(i)])\n",
    "\n",
    "get_unique_hsv_cmap()\n",
    "plt.get_cmap(\"unique_hsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(ax, path, title=\"\", invert=True, sub_image=None, cmap=\"unique_hsv\", scale=False, logscale=False, plot=True):\n",
    "    img = np.array(cv2.imread(path, cv2.IMREAD_GRAYSCALE))\n",
    "\n",
    "    if sub_image:\n",
    "        img_2 = np.array(cv2.imread(sub_image, cv2.IMREAD_GRAYSCALE))\n",
    "        # img = cv2.subtract(img, img_2)\n",
    "        img = img - img_2\n",
    "        img[img < 0] = img[img < 0] * -1\n",
    "        # img = np.abs(img - img_2)\n",
    "    \n",
    "    # # scaling\n",
    "    # if scale:\n",
    "    #     mask = (img > 0) & (img < 160)\n",
    "    #     img[mask] = np.clip(img[mask] + 40, 0, 255) # cv2.add(img[mask], 30)\n",
    "\n",
    "    # invert\n",
    "    if invert:\n",
    "        max_value = 255 # 2**(img.dtype.itemsize * 8) -1\n",
    "        scaling_func = lambda x: max_value - x\n",
    "        img = np.apply_along_axis(scaling_func, axis=0, arr=img)\n",
    "\n",
    "    # # Apply logarithmic scaling to enhance contrast in dim regions\n",
    "    # if logscale:\n",
    "    #     img = np.log1p(img)\n",
    "    #     # img /= img.max()  # normalize to [0,1]\n",
    "\n",
    "    if plot:\n",
    "        ax.axis(\"off\")\n",
    "        color_ax = ax.imshow(img, cmap=cmap)\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32531975",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "\n",
    "example_images_model, ids = get_same_pred_real_samples(f\"../../data/eval/{model_name}/pred\",\n",
    "                                                         f\"../../data/eval/{model_name}/real\",\n",
    "                                                         n_samples)\n",
    "\n",
    "pred_model = example_images_model[:n_samples]\n",
    "real = example_images_model[n_samples:] \n",
    "\n",
    "fig, ax = plt.subplots(nrows=n_samples, ncols=2, figsize=(2*4, n_samples*6))\n",
    "# ax = ax.ravel()\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"{model_name}\")\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"ground truth\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a71569",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_samples, ncols=2, figsize=(2*4, n_samples*6))\n",
    "\n",
    "ax_idx = 0\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx][0], path=cur_path, title=f\"{model_name}\", cmap=\"plasma\")\n",
    "\n",
    "for idx, cur_path in enumerate(real):\n",
    "    plot(ax[idx][1], path=cur_path, title=f\"ground truth\", cmap=\"plasma\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e582a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "\n",
    "# Create a mappable object (for the colorbar)\n",
    "norm = plt.Normalize(vmin=0, vmax=255)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"unique_hsv\", norm=norm)\n",
    "sm.set_array([])  # Required to set the color range without linking it to any image\n",
    "\n",
    "fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.05, pad=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563fc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=n_samples, ncols=1, figsize=(1*4, n_samples*6))\n",
    "\n",
    "for idx, cur_path in enumerate(pred_model):\n",
    "    plot(ax[idx], path=cur_path, title=f\"{model_name}\", sub_image=real[idx], invert=False, scale=True, cmap=\"plasma\")\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c63fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 5))\n",
    "\n",
    "# Create a mappable object (for the colorbar)\n",
    "norm = plt.Normalize(vmin=0, vmax=255)\n",
    "sm = plt.cm.ScalarMappable(cmap=\"plasma\", norm=norm)\n",
    "sm.set_array([])  # Required to set the color range without linking it to any image\n",
    "\n",
    "fig.colorbar(sm, ax=ax, orientation='vertical', fraction=0.05, pad=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd79486",
   "metadata": {},
   "source": [
    "Inspect some single images in more detail here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ec73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import block_reduce\n",
    "\n",
    "def plot_image_with_values(img, block_size=8):\n",
    "    # Compute mean over non-overlapping blocks\n",
    "    mean_img = block_reduce(img, block_size=(block_size, block_size), func=np.mean)\n",
    "    max_value = mean_img.max()\n",
    "\n",
    "    # Plot the mean image\n",
    "    plt.imshow(mean_img, cmap='gray', interpolation='nearest')\n",
    "    plt.colorbar(label='Mean Value')\n",
    "\n",
    "    # Annotate each block with the mean\n",
    "    for i in range(mean_img.shape[0]):\n",
    "        for j in range(mean_img.shape[1]):\n",
    "            val = mean_img[i, j]\n",
    "            color = 'white' if val < max_value/1.5 else 'black'\n",
    "            # color = int(255 - val)\n",
    "            plt.text(j, i, f'{val:.1f}', ha='center', va='center',\n",
    "                     color=color, fontsize=6)\n",
    "\n",
    "    plt.title(f'Mean Values over {block_size}x{block_size} Blocks')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0560b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = pred_model[0]\n",
    "img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE).astype(float)\n",
    "\n",
    "plot_image_with_values(img, block_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plot(None, path=pred_model[0], title=f\"{model_name}\", sub_image=real[idx], invert=False, scale=True, plot=False)\n",
    "plot_image_with_values(img, block_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863560e",
   "metadata": {},
   "source": [
    "### Old Code /Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9922317",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"../../data/eval/{model_name}/pred\"\n",
    "example_images = [os.path.join(path, cur_img) for cur_img in os.listdir(path)]\n",
    "print(f\"Examples from {model_name}\")\n",
    "show_images(image_paths=example_images[:10], image_width=4, cols=5, cmap=\"inferno\", color_space=\"grey\", invert=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b061b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "example_images_model, ids = get_same_pred_real_samples(f\"../../data/eval/{model_name}/pred\",\n",
    "                                                         f\"../../data/eval/{model_name}/real\",\n",
    "                                                         n_samples)\n",
    "\n",
    "# Plot the histogram\n",
    "for cur_image in example_images_model:\n",
    "    img = np.array(cv2.imread(cur_image, cv2.IMREAD_GRAYSCALE))\n",
    "    plt.hist(img.flatten(), bins=256, range=(190, 210), density=True)\n",
    "    plt.xlabel(\"Pixel Values\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Set every x-tick (e.g., every 1 value from 190 to 255)\n",
    "    plt.gca().xaxis.set_major_locator(MultipleLocator(1))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_image in example_images_model:\n",
    "    img = np.array(cv2.imread(cur_image, cv2.IMREAD_GRAYSCALE))\n",
    "    plt.hist(img.flatten(), bins=256, range=(0, 256), density=True)\n",
    "    plt.xlabel(\"Pixel Values\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09511e20",
   "metadata": {},
   "source": [
    "### Check Processed Images\n",
    "\n",
    "for quantization error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_example_images_model = []\n",
    "for cur_image in example_images_model:\n",
    "    processed_example_images_model += [plot(None, path=cur_path, title=f\"ground truth\", plot=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_image in processed_example_images_model:\n",
    "    img = cur_image\n",
    "    plt.hist(img.flatten(), bins=256, range=(0, 256), density=True)\n",
    "    plt.xlabel(\"Pixel Values\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cur_image in processed_example_images_model:\n",
    "    img = cur_image\n",
    "    plt.hist(img.flatten(), bins=256, range=(256-210, 256-190), density=True)\n",
    "    plt.xlabel(\"Pixel Values\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # Set every x-tick (e.g., every 1 value from 190 to 255)\n",
    "    plt.gca().xaxis.set_major_locator(MultipleLocator(1))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
